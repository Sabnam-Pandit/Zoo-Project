{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6cd66aa-65c2-4918-8c2f-b7fe5b149131",
   "metadata": {},
   "source": [
    "# Prof's Edited Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf436cb8-b90e-496a-8008-39759feadb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.11/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.11/site-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.11/site-packages (from librosa) (0.13.0)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.11/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/lib/python3.11/site-packages (from librosa) (4.7.1)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.11/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.11/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from lazy-loader>=0.1->librosa) (23.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2023.7.22)\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.11/site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from soundfile) (2.0.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0->soundfile) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "\n",
    "\n",
    "!pip install soundfile\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import namedtuple\n",
    "import librosa\n",
    "\n",
    "# Add-on modules, use conda or pip to install\n",
    "from librosa import display  # conda install -c conda-forge librosa\n",
    "# from librosa.util import normalize\n",
    "import numpy as np\n",
    "\n",
    "def normalize(y, axis=0):\n",
    "    \"\"\"Normalize an array along a specified axis.\"\"\"\n",
    "    return y / np.max(np.abs(y), axis=axis, keepdims=True)\n",
    "# from librosa import power_to_db\n",
    "import numpy as np\n",
    "\n",
    "def power_to_db(S, ref=1.0, amin=1e-10, top_db=80.0):\n",
    "    \"\"\"Convert a power spectrogram to decibel (dB) units.\"\"\"\n",
    "    S = np.asarray(S)\n",
    "    magnitude = 10.0 * np.log10(np.maximum(amin, S))\n",
    "    magnitude -= 10.0 * np.log10(np.maximum(amin, ref))\n",
    "    if top_db is not None:\n",
    "        magnitude = np.maximum(magnitude, magnitude.max() - top_db)\n",
    "    return magnitude\n",
    "import soundfile  # conda install -c conda-forge pysoundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458b5d4-304a-4fb1-8676-b5ae5d04efa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be9889e8-ddd4-4f9e-a180-c75034b33028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.2.post1\n"
     ]
    }
   ],
   "source": [
    "print(librosa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "136487ad-cbcc-4b7a-8345-2adbedb97614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioPool_short:\n",
    "    # Each cache entry contains a SoundFile audio file class instance, framing\n",
    "    # parameters calculated for the sample rate, and the channel to be\n",
    "    # processed.\n",
    "    EntryType = namedtuple(\"EntryType\", ('audio', \"adv_N\", \"len_N\", \"channel\"))\n",
    "\n",
    "    # Spectrogram bias to prevent log10 from taking log(0)\n",
    "    spec_bias = 1e-7\n",
    "\n",
    "    # Channel to use in multi-channel recordings when there is no\n",
    "    # channel map entry to tell us what to do.\n",
    "    default_channel = 0\n",
    "\n",
    "    def __init__(self, adv_s=0.0025, len_s=0.005, window=\"hamming\",\n",
    "                 low_Hz=0, high_Hz=None):\n",
    "        \"\"\"\n",
    "        AudioPool maintains a least recently used cache of open files.\n",
    "        Files are accessed via their filename:\n",
    "\n",
    "        pool = AudioPool()\n",
    "        soundfile_obj = pool['path/to/file.wav']\n",
    "\n",
    "        When the pool size is reached, older sounds are closed.\n",
    "\n",
    "        :param adv_s:  frame advance (s) for spectrograms\n",
    "        :param len_s:  frame length (s) for spectrograms\n",
    "        :param window: window function for spectrograms\n",
    "        :param low_Hz: lowest frequency of spectrograms (default 0 Hz)\n",
    "        :param high_Hz: highest frequency of spectrograms (default Nyquist)\n",
    "        \"\"\"\n",
    "        # Create least recently used cache of specified size\n",
    "        self.cache = {}  # Use a dictionary for simplicity\n",
    "\n",
    "        self.adv_s = adv_s\n",
    "        self.len_s = len_s\n",
    "        self.window = window\n",
    "        self.low_Hz = low_Hz\n",
    "        self.high_Hz = high_Hz\n",
    "\n",
    "    def __getitem__(self, filename):\n",
    "        \"\"\"\n",
    "        [filename] - Retrieve SoundFile instance for the specified filename\n",
    "        \"\"\"\n",
    "        if filename not in self.cache:\n",
    "            # Not in cache\n",
    "            sound = soundfile.SoundFile(filename)\n",
    "            adv_N = int(sound.samplerate * self.adv_s + 0.5)\n",
    "            len_N = int(sound.samplerate * self.len_s + 0.5)\n",
    "            channel = 0  # Assuming single channel for now\n",
    "\n",
    "            item = self.EntryType(sound, adv_N, len_N, channel)\n",
    "            self.cache[filename] = item\n",
    "\n",
    "        return self.cache[filename]\n",
    "\n",
    "    def get_spectrogram(self, filename, start_s=0, duration_s=-1):\n",
    "        \"\"\"\n",
    "        get_spectrogram - Return power spectrogram in dB rel.\n",
    "        :param filename:  audio file path\n",
    "        :param start_s: start time (s)\n",
    "        :param duration_s: duration (s)\n",
    "        :return:  frequency X time spectra in dB\n",
    "        \"\"\"\n",
    "\n",
    "        data = self.get_seconds(filename, start_s, duration_s)\n",
    "        entry = self.cache[filename]\n",
    "        Fs = entry.audio.samplerate\n",
    "\n",
    "        # Normalize data\n",
    "        data = normalize(data)\n",
    "\n",
    "        # Compute spectrogram\n",
    "       # Set n_fft relative to data length\n",
    "        # n_fft = max(256, min(1024, len(data)))  # Ensure n_fft is reasonable for short clips\n",
    "      \n",
    "        hop_length = int(self.adv_s * Fs + 0.5)\n",
    "        win_length = int(self.len_s * Fs + 0.5)\n",
    "        n_fft = win_length  # Ensure n_fft is at least win_length\n",
    "        n_fft = min(n_fft, len(data))\n",
    "\n",
    "        D = librosa.stft(data,n_fft=n_fft,\n",
    "                         hop_length=hop_length, win_length=win_length,\n",
    "                         window=self.window, center=False)\n",
    "        spectrogram = np.abs(D)\n",
    "\n",
    "        # Convert to decibels\n",
    "        spectrogram_db = power_to_db(spectrogram**2, ref=np.max(spectrogram**2))\n",
    "       \n",
    "        return spectrogram_db, Fs\n",
    "\n",
    "    def get_seconds(self, filename, start_s, duration_s=-1):\n",
    "        \"\"\"\n",
    "        Return duration_s seconds of data from filename starting at start_s\n",
    "        seconds into the file.\n",
    "\n",
    "        :param filename:  file to access\n",
    "        :param start_s:  offset into file in seconds\n",
    "        :param duration_s:   read duration seconds from start_s, to end of file if -1\n",
    "        :return:  audio data\n",
    "        \"\"\"\n",
    "\n",
    "        entry = self[filename]\n",
    "        Fs = entry.audio.samplerate\n",
    "\n",
    "        if start_s is not None:\n",
    "            start_sample = int(start_s * Fs)\n",
    "            # Ensure we are at the correct start position\n",
    "            current = entry.audio.tell()\n",
    "            if current != start_sample:\n",
    "                entry.audio.seek(start_sample)  # Move to desired position\n",
    "\n",
    "        if duration_s == -1:\n",
    "            Nsamples = -1\n",
    "        else:\n",
    "            Nsamples = int(Fs * duration_s)\n",
    "\n",
    "        data = entry.audio.read(frames=Nsamples)\n",
    "        # print(f\"Data shape: {data.shape}, Min: {data.min()}, Max: {data.max()}\")\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb972bd0-ee99-45cc-8da1-7796581379da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    audio_file=\"Audio_Files/Audio_extracted/Roch/20190611_030000.WAV\"\n",
    "    pool = AudioPool_short(len_s = 0.005)\n",
    "    spectrogram, sr = pool.get_spectrogram(audio_file, start_s = 0, duration_s = -1)\n",
    "\n",
    "    # Display the spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='linear')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Spectrogram')\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57b3ff-31ca-4811-8dee-eeb450bbcb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0157a1-5199-44fe-a90c-edecfe81a01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23040000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dfb4c67-ae8f-44bb-a5e0-89e372ceb448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23040000/384000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931ed0a-9d03-4f95-8cdb-18c9800ba5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "807d2d45-868c-45e2-ab1c-280dc4a78467",
   "metadata": {},
   "source": [
    "# Code for Spectrogram of Centroids and Closest Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e4da231-08e7-4039-a421-48cf9b35599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.11/site-packages (3.12.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.11/site-packages (from h5py) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0877f2f-492c-4535-8358-80312bd83e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "clusters = pd.read_csv('cluster_centroids_with_ids_np_array.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89fd3f8d-ef5a-4b88-aa75-46de3a0362bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = clusters['Centroid']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155ffba-d376-445b-bfb4-0809ca1b640a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in Embeddings/embed_files/20190611_030000.WAV_embeddings_Data2VecMultiModel_checkpoint_last.pt_12.h5: ['embedding', 'filename', 'time']\n",
      "Total files added: 192\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "845fed78-899d-4307-9cd6-3d4bc29532da",
   "metadata": {},
   "source": [
    "## Spectrogram of Cluster 1 two closest points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d4ae3-37be-4920-b880-8867ad551f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Assuming you have two audio files for the closest points\n",
    "audio_file_1 = \"Audio_Files/Audio_extracted/Roch/20190612_173000.WAV\"\n",
    "audio_file_2 = \"Audio_Files/Audio_extracted/Roch/20190612_174000.WAV\"  \n",
    "# Create an AudioPool_short object\n",
    "pool = AudioPool_short(len_s=0.005)\n",
    "\n",
    "# Get spectrograms for both audio files\n",
    "spectrogram_1, sr_1 = pool.get_spectrogram(audio_file_1, start_s=53.447765, duration_s=-1)\n",
    "spectrogram_2, sr_2 = pool.get_spectrogram(audio_file_2, start_s=45.561047, duration_s=-1)\n",
    "\n",
    "# Create subplots to display the two spectrograms side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot the first spectrogram\n",
    "img1 = librosa.display.specshow(spectrogram_1, sr=sr_1, x_axis='time', y_axis='linear', ax=ax[0])\n",
    "ax[0].set_title('Spectrogram 1 from Cluster 1')\n",
    "plt.colorbar(img1, ax=ax[0], format='%+2.0f dB')\n",
    "\n",
    "# Plot the second spectrogram\n",
    "img2 = librosa.display.specshow(spectrogram_2, sr=sr_2, x_axis='time', y_axis='linear', ax=ax[1])\n",
    "ax[1].set_title('Spectrogram 2 from Cluster 1 ')\n",
    "plt.colorbar(img2, ax=ax[1], format='%+2.0f dB')\n",
    "\n",
    "# Adjust layout to make it look neat\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"Cluster1 Spectrograms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00e389-431b-4bbe-aed7-86b6faa65642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e3619-a94f-447b-b10e-a92d7deee20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88aca00a-39e7-4c4a-894b-68a4ed21c7e7",
   "metadata": {},
   "source": [
    "## Spectrogram of cluster 18 ( Randomly Selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac28ce-642e-4551-9f3b-5749502f78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Assuming you have two audio files for the closest points\n",
    "audio_file_1 = \"Audio_Files/Audio_extracted/Roch/20190611_030000.WAV\"\n",
    "audio_file_2 = \"Audio_Files/Audio_extracted/Roch/20190611_045000.WAV\"  \n",
    "# Create an AudioPool_short object\n",
    "pool = AudioPool_short(len_s=0.005)\n",
    "\n",
    "# Get spectrograms for both audio files\n",
    "spectrogram_1, sr_1 = pool.get_spectrogram(audio_file_1, start_s=0.009995842, duration_s=-1)\n",
    "spectrogram_2, sr_2 = pool.get_spectrogram(audio_file_2, start_s=35.670162, duration_s=-1)\n",
    "\n",
    "# Create subplots to display the two spectrograms side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot the first spectrogram\n",
    "img1 = librosa.display.specshow(spectrogram_1, sr=sr_1, x_axis='time', y_axis='linear', ax=ax[0])\n",
    "ax[0].set_title('Spectrogram 1')\n",
    "plt.colorbar(img1, ax=ax[0], format='%+2.0f dB')\n",
    "\n",
    "# Plot the second spectrogram\n",
    "img2 = librosa.display.specshow(spectrogram_2, sr=sr_2, x_axis='time', y_axis='linear', ax=ax[1])\n",
    "ax[1].set_title('Spectrogram 2')\n",
    "plt.colorbar(img2, ax=ax[1], format='%+2.0f dB')\n",
    "\n",
    "# Adjust layout to make it look neat\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1dd50-b848-4efa-add1-8b26a9362c0b",
   "metadata": {},
   "source": [
    "## Code for all clusters in one plot randomly selectig two embeddings from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40382ed3-c9cd-48b2-be71-e87838f2aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import librosa\n",
    "import numpy\n",
    "\n",
    "print(\"Librosa version:\", librosa.__version__)\n",
    "print(\"NumPy version:\", numpy.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb70bd-ef40-4464-b6c3-a7705ca56c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def get_random_files(cluster_data, audio_directory):\n",
    "    \"\"\"\n",
    "    Extracts two random rows from the given dataframe and returns their filenames and times.\n",
    "\n",
    "    Args:\n",
    "    cluster_data (pd.DataFrame): Dataframe containing the cluster data with 'filename' and 'Time' columns.\n",
    "    audio_directory (str): Path to the directory containing audio files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing filenames and times for two random rows \n",
    "           (audio_file_1, audio_file_2, time_1, time_2).\n",
    "    \"\"\"\n",
    "    # Ensure the dataframe has at least two rows\n",
    "    if len(cluster_data) < 2:\n",
    "        raise ValueError(\"The dataframe must contain at least two rows.\")\n",
    "    \n",
    "    # Select two random indices\n",
    "    random_rows = cluster_data.sample(n=2, random_state=random.randint(0, 1000))\n",
    "\n",
    "    # Extract filenames and times\n",
    "    audio_file1 = random_rows.iloc[0]['filename']\n",
    "    # Ensure the filename does not already have '.WAV' before appending it\n",
    "    audio_file_1 = os.path.join(audio_directory, audio_file1.split('_')[0] + \"_\" + audio_file1.split('_')[1] + \".WAV\")\n",
    "    audio_file_1 = audio_file_1.replace('.WAV.WAV', '.WAV')  # Remove any accidental duplicate extensions\n",
    "    \n",
    "    audio_file2 = random_rows.iloc[1]['filename']\n",
    "    audio_file_2 = os.path.join(audio_directory, audio_file2.split('_')[0] + \"_\" + audio_file2.split('_')[1] + \".WAV\")\n",
    "    audio_file_2 = audio_file_2.replace('.WAV.WAV', '.WAV')  # Remove any accidental duplicate extensions\n",
    "        \n",
    "    time_1 = random_rows.iloc[0]['Time']\n",
    "    time_2 = random_rows.iloc[1]['Time']\n",
    "\n",
    "    # Ensure files exist\n",
    "    if not os.path.isfile(audio_file_1):\n",
    "        raise FileNotFoundError(f\"File {audio_file_1} does not exist.\")\n",
    "    if not os.path.isfile(audio_file_2):\n",
    "        raise FileNotFoundError(f\"File {audio_file_2} does not exist.\")\n",
    "    \n",
    "    return audio_file_1, audio_file_2, time_1, time_2\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('clusters_with_time_filename_mini.csv')\n",
    "\n",
    "# Assuming your 'Audio_Files' directory is in the correct path\n",
    "audio_directory = \"Audio_Files/Audio_extracted/Roch\"\n",
    "\n",
    "# Create an AudioPool_short object (make sure it's defined properly in your code)\n",
    "pool = AudioPool_short(len_s=0.005)\n",
    "\n",
    "# Set up the figure\n",
    "fig, axs = plt.subplots(20, 2, figsize=(20, 50))  # 20 clusters, 2 columns\n",
    "fig.suptitle(\"Spectrograms for All Clusters\", fontsize=16)\n",
    "\n",
    "for cluster in range(20):\n",
    "    # Filter the data for the current cluster\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    \n",
    "    # Skip clusters with less than 2 rows\n",
    "    if len(cluster_data) < 2:\n",
    "        print(f\"Skipping cluster {cluster}: Not enough data.\")\n",
    "        continue\n",
    "\n",
    "    # Get two random files for the current cluster\n",
    "    audio_file_1, audio_file_2, time_1, time_2 = get_random_files(cluster_data, audio_directory)\n",
    "\n",
    "    # Get spectrograms for both audio files\n",
    "    spectrogram_1, sr_1 = pool.get_spectrogram(audio_file_1, start_s=time_1, duration_s=-1)\n",
    "    spectrogram_2, sr_2 = pool.get_spectrogram(audio_file_2, start_s=time_2, duration_s=-1)\n",
    "\n",
    "    # Plot the first spectrogram\n",
    "    img1 = librosa.display.specshow(spectrogram_1, sr=sr_1, x_axis='time', y_axis='linear', ax=axs[cluster, 0])\n",
    "    axs[cluster, 0].set_title(f'Cluster {cluster} - Spectrogram 1')\n",
    "    axs[cluster, 0].set_ylim(0, 20000)\n",
    "    plt.colorbar(img1, ax=axs[cluster, 0], format='%+2.0f dB')\n",
    "\n",
    "    # Plot the second spectrogram\n",
    "    img2 = librosa.display.specshow(spectrogram_2, sr=sr_2, x_axis='time', y_axis='linear', ax=axs[cluster, 1])\n",
    "    axs[cluster, 1].set_title(f'Cluster {cluster} - Spectrogram 2')\n",
    "    axs[cluster, 1].set_ylim(0, 20000)  \n",
    "    plt.colorbar(img2, ax=axs[cluster, 1], format='%+2.0f dB')\n",
    "\n",
    "# Adjust layout to make it look neat\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98])  # Leave space for the title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4e2c8-a627-4030-991d-30f05777a9f6",
   "metadata": {},
   "source": [
    "## Code with audio icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98044f7f-69ff-43f7-bf8e-dfb64c92b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "# Function to load and extract a segment from an audio file\n",
    "def load_audio_clip(audio_path, start_time, duration_s):\n",
    "    \"\"\"\n",
    "    Load an audio file and extract a segment based on start_time and duration.\n",
    "\n",
    "    Args:\n",
    "    audio_path (str): Path to the audio file.\n",
    "    start_time (float): Start time of the clip in seconds.\n",
    "    duration_s (float): Duration of the clip in seconds.\n",
    "\n",
    "    Returns:\n",
    "    np.array: Extracted audio segment.\n",
    "    int: Sample rate of the audio.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=None)  # Load entire audio\n",
    "    start_sample = int(start_time * sr)  # Convert start time to samples\n",
    "    if duration_s ==-1:\n",
    "        return y, sr\n",
    "    else:\n",
    "        end_sample = int((start_time + duration_s) * sr)  # Convert duration to samples\n",
    "        return y[start_sample:end_sample], sr\n",
    "    \n",
    "\n",
    "def get_random_files(cluster_data, audio_directory):\n",
    "    \"\"\"\n",
    "    Extracts two random rows from the given dataframe and returns their filenames and times.\n",
    "\n",
    "    Args:\n",
    "    cluster_data (pd.DataFrame): Dataframe containing the cluster data with 'filename' and 'Time' columns.\n",
    "    audio_directory (str): Path to the directory containing audio files.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing filenames and times for two random rows \n",
    "           (audio_file_1, audio_file_2, time_1, time_2).\n",
    "    \"\"\"\n",
    "    if len(cluster_data) < 2:\n",
    "        raise ValueError(\"The dataframe must contain at least two rows.\")\n",
    "    \n",
    "    random_rows = cluster_data.sample(n=2, random_state=random.randint(0, 1000))\n",
    "\n",
    "    audio_file1 = random_rows.iloc[0]['filename']\n",
    "    audio_file_1 = os.path.join(audio_directory, audio_file1.split('_')[0] + \"_\" + audio_file1.split('_')[1] + \".WAV\")\n",
    "    audio_file_1 = audio_file_1.replace('.WAV.WAV', '.WAV')\n",
    "    \n",
    "    audio_file2 = random_rows.iloc[1]['filename']\n",
    "    audio_file_2 = os.path.join(audio_directory, audio_file2.split('_')[0] + \"_\" + audio_file2.split('_')[1] + \".WAV\")\n",
    "    audio_file_2 = audio_file_2.replace('.WAV.WAV', '.WAV')\n",
    "        \n",
    "    time_1 = random_rows.iloc[0]['Time']\n",
    "    time_2 = random_rows.iloc[1]['Time']\n",
    "\n",
    "    if not os.path.isfile(audio_file_1):\n",
    "        raise FileNotFoundError(f\"File {audio_file_1} does not exist.\")\n",
    "    if not os.path.isfile(audio_file_2):\n",
    "        raise FileNotFoundError(f\"File {audio_file_2} does not exist.\")\n",
    "    \n",
    "    return audio_file_1, audio_file_2, time_1, time_2\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('clusters_with_time_filename_mini.csv')\n",
    "\n",
    "audio_directory = \"Audio_Files/Audio_extracted/Roch\"\n",
    "clip_duration = 0.005\n",
    "pool = AudioPool_short(len_s=0.015)\n",
    "\n",
    "n_plots =2\n",
    "\n",
    "# Set up the figure\n",
    "fig, axs = plt.subplots(n_plots, 2, figsize=(20, 50))  # 20 clusters, 2 columns\n",
    "fig.suptitle(\"Spectrograms with Audio Players\", fontsize=16)\n",
    "\n",
    "for cluster in range(n_plots):\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    \n",
    "    if len(cluster_data) < 2:\n",
    "        print(f\"Skipping cluster {cluster}: Not enough data.\")\n",
    "        continue\n",
    "\n",
    "    audio_file_1, audio_file_2, time_1_file, time_2_file = get_random_files(cluster_data, audio_directory)\n",
    "\n",
    "    time_1 = max(0, time_1_file )\n",
    "    time_2 = max(0, time_2_file )\n",
    "\n",
    "    spectrogram_1, sr_1 = pool.get_spectrogram(audio_file_1, start_s=time_1, duration_s=-1)\n",
    "    spectrogram_2, sr_2 = pool.get_spectrogram(audio_file_2, start_s=time_2, duration_s=-1)\n",
    "\n",
    "    img1 = librosa.display.specshow(spectrogram_1, sr=sr_1, x_axis='time', y_axis='linear', ax=axs[cluster, 0])\n",
    "    axs[cluster, 0].set_title(f'Cluster {cluster} - {audio_file_1}')\n",
    "    axs[cluster, 0].set_ylim(0, 20000)\n",
    "    plt.colorbar(img1, ax=axs[cluster, 0], format='%+2.0f dB')\n",
    "\n",
    "    img2 = librosa.display.specshow(spectrogram_2, sr=sr_2, x_axis='time', y_axis='linear', ax=axs[cluster, 1])\n",
    "    axs[cluster, 1].set_title(f'Cluster {cluster} - {audio_file_2}')\n",
    "    axs[cluster, 1].set_ylim(0, 20000)  \n",
    "    plt.colorbar(img2, ax=axs[cluster, 1], format='%+2.0f dB')\n",
    "    print(time_1)\n",
    "    print(time_2)\n",
    "      # Load audio clips\n",
    "    clip_1, sr_clip_1 = load_audio_clip(audio_file_1, start_time=time_1, duration_s=-1)\n",
    "    clip_2, sr_clip_2 = load_audio_clip(audio_file_2, start_time=time_2, duration_s=-1)\n",
    "\n",
    "    # Display audio players for extracted clips\n",
    "    print(f\"Audio Clip for Cluster {cluster} - {audio_file_1}:\")\n",
    "    display(Audio(clip_1, rate=sr_clip_1, autoplay=False))\n",
    "\n",
    "    print(f\"Audio Clip for Cluster {cluster} - {audio_file_2}:\")\n",
    "    display(Audio(clip_2, rate=sr_clip_2, autoplay=False))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5851f-ac3f-413f-975f-56684d9c50d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305f64e-9486-45b9-97a4-8ce93d4df81f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b9dee3-2f3c-47dc-b6c6-d70eacb5d4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17b848-53ae-48dc-b746-9ae12dbf3e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06bf959-39cf-4d7d-998c-9f298a0b9d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03822d34-c264-4a93-a328-5d13f8e1e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Function to load and extract a segment from an audio file\n",
    "def load_audio_clip(audio_path, start_time, duration_s):\n",
    "    \"\"\"\n",
    "    Load an audio file and extract a segment based on start_time and duration.\n",
    "\n",
    "    Args:\n",
    "    audio_path (str): Path to the audio file.\n",
    "    start_time (float): Start time of the clip in seconds.\n",
    "    duration_s (float): Duration of the clip in seconds.\n",
    "\n",
    "    Returns:\n",
    "    np.array: Extracted audio segment.\n",
    "    int: Sample rate of the audio.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=None)  # Load entire audio\n",
    "    start_sample = int(start_time * sr)  # Convert start time to samples\n",
    "    end_sample = int((start_time + duration_s) * sr)  # Convert duration to samples\n",
    "    return y[start_sample:end_sample], sr\n",
    "\n",
    "# Function to get two random audio files from the cluster\n",
    "def get_random_files(cluster_data, audio_directory):\n",
    "    if len(cluster_data) < 2:\n",
    "        raise ValueError(\"The dataframe must contain at least two rows.\")\n",
    "    \n",
    "    random_rows = cluster_data.sample(n=2, random_state=random.randint(0, 1000))\n",
    "\n",
    "    audio_file1 = random_rows.iloc[0]['filename']\n",
    "    audio_file_1 = os.path.join(audio_directory, audio_file1.split('_')[0] + \"_\" + audio_file1.split('_')[1] + \".WAV\")\n",
    "    audio_file_1 = audio_file_1.replace('.WAV.WAV', '.WAV')\n",
    "    \n",
    "    audio_file2 = random_rows.iloc[1]['filename']\n",
    "    audio_file_2 = os.path.join(audio_directory, audio_file2.split('_')[0] + \"_\" + audio_file2.split('_')[1] + \".WAV\")\n",
    "    audio_file_2 = audio_file_2.replace('.WAV.WAV', '.WAV')\n",
    "        \n",
    "    time_1 = random_rows.iloc[0]['Time']\n",
    "    time_2 = random_rows.iloc[1]['Time']\n",
    "\n",
    "    if not os.path.isfile(audio_file_1):\n",
    "        raise FileNotFoundError(f\"File {audio_file_1} does not exist.\")\n",
    "    if not os.path.isfile(audio_file_2):\n",
    "        raise FileNotFoundError(f\"File {audio_file_2} does not exist.\")\n",
    "    \n",
    "    return audio_file_1, audio_file_2, time_1, time_2\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('clusters_with_time_filename_mini.csv')\n",
    "\n",
    "audio_directory = \"Audio_Files/Audio_extracted/Roch\"\n",
    "clip_duration = 0.005  # 5ms window before and after the embedding time\n",
    "extra_time = 0.005  # Extra 5ms for left and right padding\n",
    "\n",
    "pool = AudioPool_short(len_s=0.015)\n",
    "\n",
    "n_plots = 2\n",
    "\n",
    "# Set up the figure\n",
    "fig, axs = plt.subplots(n_plots, 2, figsize=(20, 10))  # 2 rows (for n_plots clusters), 2 columns\n",
    "fig.suptitle(\"Spectrograms with Audio Players\", fontsize=16)\n",
    "\n",
    "for cluster in range(n_plots):\n",
    "    cluster_data = df[df['Cluster'] == cluster]\n",
    "    \n",
    "    if len(cluster_data) < 2:\n",
    "        print(f\"Skipping cluster {cluster}: Not enough data.\")\n",
    "        continue\n",
    "\n",
    "    audio_file_1, audio_file_2, time_1_file, time_2_file = get_random_files(cluster_data, audio_directory)\n",
    "\n",
    "    # Adjust start and end times with padding (5ms before and after)\n",
    "    time_1_start = max(0, time_1_file - extra_time)\n",
    "    # time_1_end = time_1_file + clip_duration + extra_time\n",
    "    time_1_end = time_1_start + 0.015  # Ensure 15ms coverage\n",
    "\n",
    "\n",
    "    time_2_start = max(0, time_2_file - extra_time)\n",
    "    # time_2_end = time_2_file + clip_duration + extra_time\n",
    "    time_2_end = time_2_start + 0.015  # Ensure 15ms coverage\n",
    "\n",
    "\n",
    "    # Generate spectrograms\n",
    "    spectrogram_1, sr_1 = pool.get_spectrogram(audio_file_1, start_s=time_1_start, duration_s=time_1_end - time_1_start+0.001)\n",
    "    spectrogram_2, sr_2 = pool.get_spectrogram(audio_file_2, start_s=time_2_start, duration_s=time_2_end - time_2_start+0.001)\n",
    "\n",
    "    # Plot spectrogram 1\n",
    "    img1 = librosa.display.specshow(spectrogram_1, sr=sr_1, x_axis='time', y_axis='linear', ax=axs[cluster, 0])\n",
    "    axs[cluster, 0].set_title(f'Cluster {cluster} - {audio_file_1}')\n",
    "    axs[cluster, 0].set_ylim(0, 20000)\n",
    "    plt.colorbar(img1, ax=axs[cluster, 0], format='%+2.0f dB')\n",
    "\n",
    "    # Draw vertical lines for embedding time duration\n",
    "    axs[cluster, 0].axvline(x=time_1_file - time_1_start, color='g', linestyle='--', label=\"Embedding Start\")\n",
    "    axs[cluster, 0].axvline(x=time_1_end - time_1_file, color='g', linestyle='-.', label=\"Embedding End\")\n",
    "    axs[cluster, 0].legend()\n",
    "\n",
    "    # Plot spectrogram 2\n",
    "    img2 = librosa.display.specshow(spectrogram_2, sr=sr_2, x_axis='time', y_axis='linear', ax=axs[cluster, 1])\n",
    "    axs[cluster, 1].set_title(f'Cluster {cluster} - {audio_file_2}')\n",
    "    axs[cluster, 1].set_ylim(0, 20000)  \n",
    "    # axs[cluster, 1].set_xlim(time_1_start, time_1_end)  \n",
    "    plt.colorbar(img2, ax=axs[cluster, 1], format='%+2.0f dB')\n",
    "\n",
    "    # Draw vertical lines for embedding time duration\n",
    "    axs[cluster, 1].axvline(x=time_2_file - time_2_start, color='g', linestyle='--', label=\"Embedding Start\")\n",
    "    axs[cluster, 1].axvline(x=time_2_end - time_2_file, color='g', linestyle='-.', label=\"Embedding End\")\n",
    "    axs[cluster, 1].legend()\n",
    "\n",
    "    print(f\"Embedding Time Range for {audio_file_1}: {time_1_file} to {time_1_end}\")\n",
    "    print(f\"Embedding Time Range for {audio_file_2}: {time_2_file} to {time_2_end}\")\n",
    "\n",
    "    # Load and display audio clips\n",
    "    clip_1, sr_clip_1 = load_audio_clip(audio_file_1, start_time=time_1_start, duration_s=(time_1_end - time_1_start))\n",
    "    clip_2, sr_clip_2 = load_audio_clip(audio_file_2, start_time=time_2_start, duration_s=(time_2_end - time_2_start))\n",
    "\n",
    "    print(f\"Audio Clip for Cluster {cluster} - {audio_file_1}:\")\n",
    "    display(Audio(clip_1, rate=sr_clip_1, autoplay=False))\n",
    "\n",
    "    print(f\"Audio Clip for Cluster {cluster} - {audio_file_2}:\")\n",
    "    display(Audio(clip_2, rate=sr_clip_2, autoplay=False))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e42705-fab9-4faf-9d4a-fa76be71c30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
